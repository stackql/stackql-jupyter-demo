{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run includes/shared-setup.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load DataFrame from pickle\n",
    "resources_df = pd.read_pickle('/tmp/resources_df.pkl')\n",
    "\n",
    "with open('/tmp/all_projects.pkl', 'rb') as f:\n",
    "    all_projects = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contact Center AI Platform - Contact Centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# google.contactcenteraiplatform\n",
    "queries = [\n",
    "    f\"\"\"\n",
    "    SELECT *, '{project}' as project\n",
    "    FROM google.contactcenteraiplatform.locations\n",
    "    WHERE projectsId = '{project}'\n",
    "    \"\"\"\n",
    "    for project in all_projects\n",
    "]\n",
    "locations_df = run_stackql_queries(queries)\n",
    "locations = locations_df['locationId'].unique().tolist()\n",
    "enabled_projects = locations_df['project'].unique().tolist()\n",
    "\n",
    "queries = [\n",
    "    f\"\"\"\n",
    "    SELECT \n",
    "    displayName\n",
    "    ,SPLIT_PART(name, '/', 6) as name\n",
    "    ,'{project}' as project\n",
    "    ,'{location}' as location\n",
    "    ,state\n",
    "    ,customerDomainPrefix\n",
    "    ,JSON_EXTRACT(adminUser, '$.givenName') || ' ' || JSON_EXTRACT(adminUser, '$.familyName') as adminUser\n",
    "    ,userEmail\n",
    "    ,JSON_EXTRACT(instanceConfig, '$.instanceSize') as chatBotUri\n",
    "    ,JSON_EXTRACT(uris, '$.chatBotUri') as chatBotUri\n",
    "    ,JSON_EXTRACT(uris, '$.mediaUri') as mediaUri\n",
    "    ,kmsKey\n",
    "    FROM google.contactcenteraiplatform.contact_centers\n",
    "    WHERE projectsId = '{project}' AND locationsId = '{location}'\n",
    "    \"\"\"\n",
    "    for project in enabled_projects\n",
    "    for location in locations\n",
    "]\n",
    "_df = run_stackql_queries(queries)\n",
    "_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artifact Registry Respositories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# google.artifactregistry\n",
    "queries = [\n",
    "    f\"\"\"\n",
    "    SELECT *, '{project}' as project\n",
    "    FROM google.artifactregistry.locations\n",
    "    WHERE projectsId = '{project}'\n",
    "    \"\"\"\n",
    "    for project in artifactregistry_projects\n",
    "]\n",
    "locations_df = run_stackql_queries(queries)\n",
    "locations = locations_df['locationId'].unique().tolist()\n",
    "enabled_projects = locations_df['project'].unique().tolist()\n",
    "\n",
    "queries = [\n",
    "    f\"\"\"\n",
    "    SELECT \n",
    "    SPLIT_PART(name, '/', 6) as name\n",
    "    ,'{project}' as project\n",
    "    ,'{location}' as location\n",
    "    ,mode\n",
    "    ,(sizeBytes/1048576.0) as sizeMB\n",
    "    ,createTime\n",
    "    FROM google.artifactregistry.repositories\n",
    "    WHERE projectsId = '{project}' AND locationsId = '{location}'\n",
    "    \"\"\"\n",
    "    for project in artifactregistry_projects\n",
    "    for location in locations\n",
    "]\n",
    "_df = run_stackql_queries(queries)\n",
    "_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log Sinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# log sinks\n",
    "folder_rows = resources_df[resources_df['resType'] == 'folder']\n",
    "foldersIds = folder_rows['name'].str.split('/').str[-1].tolist()\n",
    "\n",
    "project_rows = resources_df[resources_df['resType'] == 'folder']\n",
    "projectsIds = project_rows['displayName'].tolist()\n",
    "\n",
    "org_id = '421482594427'\n",
    "\n",
    "# org log sink\n",
    "queries = [\n",
    "    f\"\"\"\n",
    "    SELECT \n",
    "    name\n",
    "    ,'organization' as level\n",
    "    ,'{org_id}' as id\n",
    "    ,description\n",
    "    ,destination\n",
    "    ,writerIdentity\n",
    "    ,includeChildren\n",
    "    FROM google.logging.sinks\n",
    "    WHERE organizationsId = '{org_id}' and writerIdentity is not null\n",
    "    \"\"\"\n",
    "]\n",
    "org_log_sinks_df = run_stackql_queries(queries)\n",
    "\n",
    "# folder log sinks\n",
    "queries = [\n",
    "    f\"\"\"\n",
    "    SELECT \n",
    "    name\n",
    "    ,'folder' as level\n",
    "    ,'{foldersId}' as id\n",
    "    ,description\n",
    "    ,destination\n",
    "    ,writerIdentity\n",
    "    ,includeChildren\n",
    "    FROM google.logging.sinks\n",
    "    WHERE foldersId = '{foldersId}' and writerIdentity is not null\n",
    "    \"\"\"\n",
    "    for foldersId in foldersIds\n",
    "]\n",
    "folder_log_sinks_df = run_stackql_queries(queries)\n",
    "\n",
    "# project log sinks\n",
    "queries = [\n",
    "    f\"\"\"\n",
    "    SELECT \n",
    "    name\n",
    "    ,'project' as level\n",
    "    ,'{projectsId}' as id\n",
    "    ,description\n",
    "    ,destination\n",
    "    ,writerIdentity\n",
    "    ,includeChildren\n",
    "    FROM google.logging.sinks\n",
    "    WHERE projectsId = '{projectsId}' and writerIdentity is not null\n",
    "    \"\"\"\n",
    "    for projectsId in projectsIds\n",
    "]\n",
    "project_log_sinks_df = run_stackql_queries(queries)\n",
    "\n",
    "pd.concat([org_log_sinks_df, folder_log_sinks_df, project_log_sinks_df], ignore_index=True)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
