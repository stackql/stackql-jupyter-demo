{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext ext.stackql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## imports and object instantiation\n",
    "import json, time, itertools, sys, threading, psycopg2\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "from IPython.display import clear_output, display, Markdown, HTML\n",
    "from ipytree import Tree, Node\n",
    "from psycopg2.extras import RealDictCursor\n",
    "from psycopg2 import ProgrammingError\n",
    "\n",
    "conn = psycopg2.connect(\"dbname=stackql user=stackql host=localhost port=5444\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_id = widgets.Text(\n",
    "    placeholder='12345',\n",
    "    description='GCP Org ID',\n",
    "    disabled=False\n",
    ")\n",
    "display(org_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## functions\n",
    "\n",
    "def display_cards(cards_data):\n",
    "    cards_html = ''\n",
    "    \n",
    "    for title, value in cards_data:\n",
    "        card_template = f\"\"\"\n",
    "        <div style=\"\n",
    "            border: 1px solid #e3e3e3;\n",
    "            border-radius: 4px;\n",
    "            padding: 20px;\n",
    "            display: inline-block;\n",
    "            margin: 5px;\n",
    "            text-align: center;\n",
    "            width: 150px;\n",
    "            background-color: #f7f7f7;\">\n",
    "            <h4 style=\"margin: 5px 0;\">{title}</h4>\n",
    "            <span style=\"font-size: 30px; font-weight: bold; color: red;\">{value}</span>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        cards_html += card_template\n",
    "    \n",
    "    display(HTML(cards_html))\n",
    "\n",
    "def get_icon(resType):\n",
    "    if resType == \"project\":\n",
    "        return 'codepen'\n",
    "    else:\n",
    "        return resType\n",
    "\n",
    "def print_overwrite(message):\n",
    "    clear_output(wait=True)\n",
    "    print(message)\n",
    "\n",
    "def build_tree_node(df, parent_name, parent_node=None):\n",
    "    children = df[df['parentDisplayName'] == parent_name]\n",
    "    \n",
    "    for _, child in children.iterrows():\n",
    "        child_node = Node(child['displayName'], opened=False, icon=get_icon(child['resType']))\n",
    "        if parent_node:\n",
    "            parent_node.add_node(child_node)\n",
    "        build_tree_node(df, child['displayName'], child_node)\n",
    "\n",
    "def explode_json_list_col(input_df, col_to_explode, exploded_col):\n",
    "    # Load JSON strings to lists where applicable and keep others as they are\n",
    "    input_df[col_to_explode] = input_df[col_to_explode].apply(lambda x: json.loads(x) if isinstance(x, str) else x)\n",
    "    \n",
    "    # Explode the lists\n",
    "    exploded_df = input_df.explode(col_to_explode)\n",
    "    \n",
    "    # If the exploded column is empty, simply return the dataframe\n",
    "    if exploded_df[col_to_explode].empty:\n",
    "        return exploded_df\n",
    "\n",
    "    # Determine the type of the elements in the exploded list\n",
    "    non_na_elements = exploded_df[col_to_explode].dropna()\n",
    "\n",
    "    if not non_na_elements.empty:\n",
    "        first_non_na = non_na_elements.iloc[0]\n",
    "        \n",
    "        # If elements are dicts, further explode their keys\n",
    "        if isinstance(first_non_na, dict):\n",
    "            for key in first_non_na.keys():\n",
    "                exploded_df[f\"{exploded_col}_{key}\"] = exploded_df[col_to_explode].apply(lambda x: x.get(key) if isinstance(x, dict) else None)\n",
    "            exploded_df.drop(columns=[col_to_explode], inplace=True)\n",
    "        else:\n",
    "            exploded_df.rename(columns={col_to_explode: exploded_col}, inplace=True)\n",
    "\n",
    "    return exploded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_stackql_query(query, debug=False):\n",
    "    try:\n",
    "        with conn.cursor(cursor_factory=RealDictCursor) as cur:\n",
    "            cur.execute(query)\n",
    "            rows = cur.fetchall()\n",
    "            return pd.DataFrame(rows)\n",
    "    except Exception as e:\n",
    "        if debug:\n",
    "            print(f\"Error executing query: {str(e)}\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_stackql_queries(queries, debug=False):\n",
    "    start_time = time.time()\n",
    "    all_results = []\n",
    "    \n",
    "    with conn.cursor(cursor_factory=RealDictCursor) as cur:\n",
    "        for query in queries:\n",
    "            if debug:\n",
    "                print(f\"Executing: {query}...\")\n",
    "            cur.execute(query)\n",
    "\n",
    "            try:\n",
    "                results = cur.fetchall()\n",
    "                if results:  # check if the result is not empty\n",
    "                    all_results.extend(results)\n",
    "            except ProgrammingError:\n",
    "                continue  # No results for this query, move on to the next one\n",
    "\n",
    "    df = pd.DataFrame(all_results)\n",
    "\n",
    "    # Check if 'error' column exists in df\n",
    "    if 'error' in df.columns:\n",
    "        df = df[df['error'].isnull()].drop(columns=['error'], inplace=False)\n",
    "\n",
    "    number_of_rows = df.shape[0]\n",
    "    elapsed_time = round(time.time() - start_time)\n",
    "\n",
    "    print(f\"Found {number_of_rows} rows in {elapsed_time} seconds\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_and_format(entity_id, query_fn, parent_display_name, res_type):\n",
    "    df = run_stackql_query(query_fn(entity_id))\n",
    "    df[\"parentDisplayName\"] = parent_display_name\n",
    "    df[\"resType\"] = res_type\n",
    "    return df\n",
    "\n",
    "def get_resources_recursive(entity_id, get_projects_query_fn, get_folders_query_fn, parent_display_name='organization'):\n",
    "    dfs = []  # List to store DataFrames\n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        future_project = executor.submit(query_and_format, entity_id, get_projects_query_fn, parent_display_name, \"project\")\n",
    "        future_folder = executor.submit(query_and_format, entity_id, get_folders_query_fn, parent_display_name, \"folder\")\n",
    "\n",
    "        projects_df = future_project.result()\n",
    "        print_overwrite(f\"Found {len(projects_df)} projects in {entity_id}\")\n",
    "        dfs.append(projects_df)\n",
    "\n",
    "        folders_df = future_folder.result()\n",
    "        print_overwrite(f\"Found {len(folders_df)} folders in {entity_id}\")\n",
    "        dfs.append(folders_df)\n",
    "\n",
    "        # Parallelize the fetching of child resources\n",
    "        folder_futures = [executor.submit(get_resources_recursive, folder['name'], get_projects_query_fn, get_folders_query_fn, folder['displayName']) \n",
    "                          for _, folder in folders_df.iterrows() if 'name' in folder]\n",
    "        \n",
    "        for future in as_completed(folder_futures):\n",
    "            dfs.append(future.result())\n",
    "\n",
    "    # Concatenate all collected DataFrames at once\n",
    "    resources_df = pd.concat(dfs, ignore_index=True)\n",
    "    return resources_df\n",
    "\n",
    "def get_all_resources(get_projects_query, get_folders_query, org_id):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Start with the root organization to get all resources\n",
    "    resources_df = get_resources_recursive(\"organizations/%s\" % (org_id), get_projects_query, get_folders_query)\n",
    "    \n",
    "    # Create root node and build the tree\n",
    "    root = Node(\"organization\", opened=False, icon='building')\n",
    "    build_tree_node(resources_df, \"organization\", root)\n",
    "    \n",
    "    # Display the tree\n",
    "    tree = Tree(nodes=[root])\n",
    "    \n",
    "    # Calculate metrics and display\n",
    "    elapsed_time = round(time.time() - start_time)\n",
    "    num_folders = resources_df.query(\"resType == 'folder'\").shape[0]\n",
    "    num_projects = resources_df.query(\"resType == 'project'\").shape[0]\n",
    "    projects = resources_df.query(\"resType == 'project'\")['projectId'].dropna().tolist()\n",
    "    \n",
    "    print(f\"Total elapsed time: {elapsed_time} seconds\")\n",
    "    cards_data = [(\"Number of Projects\", num_projects), (\"Number of Folders\", num_folders)]\n",
    "    display_cards(cards_data)\n",
    "    \n",
    "    return resources_df, projects, tree"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
